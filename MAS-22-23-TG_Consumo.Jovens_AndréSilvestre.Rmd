--- 
title: "MAS: Trabalho de Grupo"
author: "nome do representante do grupo"
date: "21 de março, 2023"
output: word_document
---

# André Filipe Gomes Silvestre

O Trabalho de Grupo de *Métodos de Aprendizagem Supervisionada* refere-se à análise do data set "Consumo.Jovens.csv". 

Neste data set incluem-se 1523 registos e 28 atributos listados a seguir:

**q0**: País de residência  
**q1**: Sexo  
**q2**: Idade  
**q3**: Situação estudantil  
**q10**: Compra produtos de marca? (1-Sim; 2-Não)  
**q12b_a**: Compra em centros comerciais? (1-Sim; 0-Não)  
**q12b_b**: Compra em super/hipermercados? (1-Sim; 0-Não)  
**q12b_c**: Compra no comércio local? (1-Sim; 0-Não)  
**q13a**: Fidelidade a marcas? (1-Sim; 0-Não)  
**q13b**: Fidelidade a lojas? (1-Sim; 0-Não)  

Variáveis q14 na Escala 1-Nada Importante, 2, 3, 4, 5-Extremamente importante)   
**q14a**: Preço  
**q14b**: Necessidade do produto  
**q14c**: Conveniência da localização da loja  
**q14d**: Qualidade do produto  
**q14e**: Imagem do produto  
**q14f**: Imagem da loja  
**q14g**: Características do produto  
**q14h**: Promoção especial  
**q14i**: Imagem da marca  
**q14j**: Publicidade  

Variáveis q19 na Escala 1-Discordo Completamente, 2, 3, 4, 5-Concordo Completamente)  
**q19_1**: Alguns dos feitos + importantes da vida incluem adquirir bens materiais  
**q19_2**: Não dou importância à quantidade de bens materiais  
**q19_3**: Gosto de ter coisas para impressionar as pessoas    
**q19_4**: Geralmente compro apenas aquilo de que preciso  
**q19_5**: Gosto de gastar dinheiro em coisas que não são necessárias  
**q19_6**: Comprar coisas dá-me imenso prazer  
**q19_7**: Tenho todas as coisas de que preciso para ser feliz  
**q19_8**: Seria mais feliz se tivesse dinheiro para comprar mais coisas   



# Notas:
1. Efetuar todos os Save com "Save with encoding UTF-8" de modo a manter palavras acentuadas e caracteres especiais**
2. A cotação está anexa a cada pergunta 
3. **OS ALUNOS QUE NÃO SUBMETEREM PDF NO MOODLE TERÃO UMA PENALIZAÇÃO DE 1 VALOR; SE, O FICHEIRO ALTERNATIVO QUE SUBMETEREM (VIA EMAIL) REPORTAR ERROS NA COMPILAÇÃO, TERÃO UMA PENALIZAÇÃO ADICIONAL DE 1 VALOR**  
  
  

```{r message=FALSE, warning=FALSE}
# Remover tudo!
rm(list=ls(all=TRUE))

# Incluir as libraries de que necessita
library(MASS)        # The MASS library contains the Boston data set 
library(Metrics)     # To help calculating metrics
library(ggplot2)     # To provide graphics
library(lsr)         # For ETA and Cramer's V measure of association
library(caret)       # Cross-validation + Metrics for classification
library(e1071)       # For classification with Naïve Bayes
library(FNN)         # Implementing KNN - K-Nearest Neighbour
library(car)         # To verify multicolinearity
library(psych)       # For some descriptives
library(nnet)        # For Multinomial Logistic Regression
library(knitr)       # To pretty outputs
library(tree)        # For Classification Tree
```


\newpage

# 1.	Leitura dos dados "Consumo.Jovens.csv" e análise preliminar dos mesmos  

## 1.1) [1 valor] Leitura dos dados; apresentação de dimensão e estrutura dos dados; verificação do número de casos com dados em falta (para todos os atributos); sumário dos dados completos (depois de eliminação dos casos/linhas com dados omissos )
  

```{r}
# Leitura dos dados (Nota: verifique sep no ficheiro de origem)
CJ <- read.csv("Consumo.Jovens.csv", header=TRUE, dec=".",na.strings="", sep=";",stringsAsFactors = TRUE)
CJ_original <- CJ

# Apresentação de dimensão e estrutura dos dados.  
dim(CJ)
print(paste("Nº de Observações:", nrow(CJ)))
print(paste("Nº de Colunas:", ncol(CJ)))
str(CJ)

# Verificação do número de casos com dados em falta (para todos os atributos) 
colSums(is.na(CJ)) # NAs por atributo
paste("No total, existem", nrow(is.na(CJ)), "NAs.")

# Eliminação dos casos/linhas com dados omissos 
CJ<-na.omit(CJ)

# Sumário dos dados completos
summary(CJ)
```

## 1.2) [1.5 valores] Breve análise descritiva de q0, q1, q2 e q3.

```{r}
#q0: País de residência - Tabela de Frequências Absolutas e Relativas e Gráfico de Pizza
table(CJ[,1])
prop.table(table(CJ[,1]))
pie(table(CJ[,1]), main = "Gráfico de Pizza do País de Residência")

#q1: Sexo - Tabela de Frequências Absolutas e Relativas e BarPlot
table(CJ[,2])
prop.table(table(CJ[,2]))
barplot(table(CJ[,2]), ylim=c(0,1000), main = "Gráfico de Barras do Sexo")

#q2: Idade - Métricas para variaveis quantitativas e Histograma
describe(CJ[,3])
hist(CJ[,3], freq = F, ylim = c(0,.5), xlim = c(16.5, 25.5), main = "Histograma da Idade")

#q3: Situação Estudantil - Tabela de Frequências Absolutas e Relativas e BarPlot
table(CJ[,4])
prop.table(table(CJ[,4]))
pie(table(CJ[,4]), main = "Gráfico de Pizza da Situação Estudantil")

```

## 1.3) [1.5 valores] Cálculo (e apresentação) de medidas de associação entre as variáveis: 

- a)  q14a…q14j; 
- b) q0 e as variáveis q19_1…q19_8; 
- c) q10 e q1

```{r}
#a) q14a…q14j - Correlação de Pearson 
# Medir a correlação dos preditores métricos
(corr <- round(cor(CJ[, 11:20], method = "pearson"), 2))

#b) q0 e as variáveis q19_1…q19_8 - ETA 
# Associação entre o target categórico e os preditores métricos 
eta<- matrix(0,8,1)
rownames(eta)<-colnames(CJ[,21:28]) 

for (i in 21:28) { 
  anova_ <- aov(CJ[,i] ~ q0, CJ)
  eta[i-20]<-sqrt(etaSquared(anova_ )[,1]) 
} 

eta

# c) q10 e q1 - V de Cramer 
# Medir a associação entre preditores qualitativos e o target
cramersV(CJ$q1,CJ$q10)
```


## 1.4) [1 valor] Divisão dos dados em amostra de treino (60%)- CJ.train - e de teste (40%) – CJ.test - usando set.seed(444);apresentação de tabela de frequências relativas de q1 em cada amostra

```{r}
# Definir o set.seed para permitir reprodutibilidade dos resultados
set.seed(444)

# Divisão em Conjunto Treino/Teste
ind_train <- sample(nrow(CJ),0.6*nrow(CJ)) 

# Conjunto Treino (CJ.train)
CJ.train <- CJ[ind_train,] 
paste("O Conjunto de Treino tem", nrow(CJ.train),"observações.")

# Tabela de frequências relativas da variável q1 - Conjunto de Treino
prop.table(table(CJ.train$q1))

# Conjunto Teste (CJ.test)
CJ.test <- CJ[-ind_train,] 
paste("O Conjunto de Teste tem", nrow(CJ.test),"observações.")

# Tabela de frequências relativas da variável q1 - Conjunto de Teste
prop.table(table(CJ.test$q1))
```

## 1.5) [1 valor] Completação das frases seguintes:

Inicialmente, o número de casos omissos na variável q1 era **` r sum(is.na(CJ_original$q1))`**. No conjunto de dados em análise (depois de eliminar os registos com observações omissas) o número de estudantes trabalhadores é igual a **`r as.vector(table(CJ[,4])[1])`**. A correlação mais elevada entre o pares de variáveis q14 tem o valor **`r max(abs(corr[corr!=1]))`**. A correlação maior entre a variável q0 e as variáveis q19_ regista-se para a variável **q19_3**

```{r}
# 1 - sum(is.na(CJ_original$q1))
# 2 - as.vector(table(CJ[,4])[1])
# 3 - max(abs(corr[corr!=1]))
# 4 - q19_3
```

\newpage


# 2. Regressão: utilização do K-Nearest Neighbour para prever q19_8 com base nas variáveis q12b_a , q12b_b, q12b_c, q13a e q13b.

## 2.1) [2 valores] Aprendizagem sobre CJ.train[,c(6:10)] e considerando y=y=CJ.train$q19_8 recorrendo a one-hold-out validation; determinação de um “melhor” valor de K atendendo ao Sum of Squares Error

### Fórmula do Sum of Squares Error (SSE)

$$\sum\left(y_i-{\hat{y}}_i\right)^2$$

```{r}
# Modelo de KNN com o target "q19_8" e preditor "q12b_a", "q12b_b", "q12b_c", "q13a" e "q13b" 
# Seleção do "melhor" k de acordo com o SSE

k.sse<-matrix(NA,50,2)

for (i in 1:50){
  knn.CJ <- knn.reg(CJ.train[,c(6:10)], y=CJ.train$q19_8, k=i)
  k.sse[i,1]<-i 
  k.sse[i,2] <- sse(knn.CJ$pred, CJ.train$q19_8)
}

# Representação Gráfica da SSE
plot(k.sse[,2], type = "b", pch = 19, xlab = "K Value", ylab = "Sum of Squares Error")

# Ordenar o SSE
k.sse<-k.sse[order(k.sse[,2],decreasing=FALSE),]

# "Melhor" k segundo o SSE
best_k <- k.sse[1,1]
paste("O 'melhor' K utilizando esta metedologia é", best_k)
```

## 2.2) [2 valores] Considerando o “melhor” valor de K (v. 2.1), obtenção de estimativas do alvo e listagem dos 6 primeiros valores estimados nos conjuntos CJ.train e CJ.test  

```{r}
# Estimativas sobre CJ.train
knn.CJ_train <- knn.reg(CJ.train[,c(6:10)], y = CJ.train$q19_8, k = best_k)
head(knn.CJ_train$pred, 6)

# Estimativas sobre CJ.test 
knn.CJ_test <- knn.reg(CJ.train[,c(6:10)], CJ.test[,c(6:10)], y = CJ.train$q19_8, k = best_k)
head(knn.CJ_test$pred, 6)
```

## 2.3) [2 valores] Determinação de Sum of Squares Error e de Root Mean Squared Error (RMSE) correspondentes às estimativas obtidas pelo KNN em 2.2) para as amostras CJ.train e CJ.test

### Fórmula do Sum of Squares error (SSE)

$$\sum\left(y_i-{\hat{y}}_i\right)^2$$

### Fórmula do Root Mean Squared Error (RMSE)

$$\sqrt{\frac{\sum\left(y_i-{\hat{y}}_i\right)^2}{n}}$$

```{r}
# Métricas sobre CJ.train
train_sse <- sse(knn.CJ_train$pred, CJ.train$q19_8)
train_rmse <- rmse(knn.CJ_train$pred, CJ.train$q19_8)
cat("SSE para CJ.train:", round(train_sse,2), "\n")
cat("RMSE para CJ.train:", train_rmse, "\n")

# Métricas sobre CJ.test
test_sse <- sse(knn.CJ_test$pred, CJ.test$q19_8)
test_rmse <- rmse(knn.CJ_test$pred, CJ.test$q19_8)
cat("SSE para CJ.test:", round(test_sse,2), "\n")
cat("RMSE para CJ.test:", test_rmse, "\n")
```

## 2.4) [1 valor] Completação das frases seguintes:

O “melhor” valor de K, para K-NN, obtido segundo validação hold-one-out sobre a amostra de treino é **`r k.sse[1,1]`**; o valor estimado do alvo para a 1ª observação do conjunto de teste é **`r knn.CJ_test$pred[1]`**;  neste conjunto (teste) obtém-se um RMSE de **`r round(test_rmse,2)`** e um SSE de **`r round(test_sse,2)`**. 

```{r}
# 1 - k.sse[1,1]
# 2 - knn.CJ_test$pred[1]
# 3 - test_rmse
# 4 - test_sse
```

\newpage

# 3. Classificação: utilização de uma Árvore para prever q10 (Compra ou não compra produtos de marca) considerando 4 preditores: q12b_a, q13a, q14e e q14i.  

## 3.1) [2 valores] Construção de uma Árvore de classificação sobre CJ.train efetuando a sua poda de modo a fixar 15 nós folha (para prever q10 com base nos preditores q12b_a, q13a, q14e e q14i) 

```{r}
# ======================== Árvore de Classificação ========================

# Nomes das Variáveis
colnames(CJ.train)

# Começamos por criar uma Árvore Grande
ctree_large <-tree(q10~q12b_a+q13a+q14e+q14i, data = CJ.train, 
                   control=tree.control(nrow(CJ.train),
                                        mincut = 1, minsize = 2,
                                        mindev = 0.001),
                   split = "deviance")

# Resultados da Árvore
summary(ctree_large)


### Custo-Complexidade - Poda da Árvore

# Gráfico de Custo/Complexidade
seq_ctree_prune <- prune.tree(ctree_large)
plot(seq_ctree_prune$size,seq_ctree_prune$dev,pch =20)
lines(seq_ctree_prune$size,seq_ctree_prune$dev, col = "red")

# Utilizando o "melhor" tamanho de 15 como referido no enunciado, obtermos a seguinte Árvore Podada
ctree.CJ<-prune.tree(ctree_large, best=15)
```

## 3.2) [2 valores] Representações da Árvore de Classificação: a) Lista indentada; b) Gráfico da Árvore 

```{r}
# a) Representações da Árvore de Classificação - Lista indentada
ctree.CJ

# b) Representações da Árvore de Classificação - Gráfico da Árvore 
plot(ctree.CJ, type="uniform")
text(ctree.CJ, pretty =0, cex=0.8)
title(main = "Prunned Classification Tree for q10")
```

## 3.3) [2 valores] Obtenção, sobre as amostras CJ.train e CJ.test, das "Matrizes de Confusão" e correspondentes medidas Accuracy associadas à Árvore de Classificação 

### Accuracy

$$\frac{TP+TN}{TP+FN+FP+TN}$$

```{r}
# "Matriz de Confusão" sobre CJ.train
pred_ctree.CJ_train<-predict(ctree.CJ, CJ.train, type = "class")

confusion_mat_tree_train <- table(CJ.train$q10, pred_ctree.CJ_train)
confusion_mat_tree_train

# Accuracy sobre CJ.train
(accuracy.train <- sum(diag(confusion_mat_tree_train))/sum(confusion_mat_tree_train))

# "Matriz de Confusão" sobre CJ.test
pred_ctree.CJ_test<-predict(ctree.CJ , CJ.test, type = "class")

confusion_mat_tree_test <- table(CJ.test$q10, pred_ctree.CJ_test)
confusion_mat_tree_test

# Accuracy sobre CJ.test
(accuracy.test <- sum(diag(confusion_mat_tree_test))/sum(confusion_mat_tree_test))
```

## 3.4) [1 valor] Completação das frases seguintes:

A árvore obtida, classifica as observações do nó folha 73) na classe **Não**; o nó folha com o maior número de observações de treino é o nó **14)**; no conjunto de teste o número de observações corretamente classificadas nas classes "Não" e "Sim" é **158** e **203**. respetivamente.

