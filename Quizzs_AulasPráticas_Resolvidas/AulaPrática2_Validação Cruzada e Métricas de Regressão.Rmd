---
title: "MAS | Aula Prática 2 - Validação Cruzada e Métricas de Regressão"
author: "André Silvestre Nº104532 CDB1"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Exemplo de Regressão Simples sobre dataset `Boston`

- Margarida G. M. S. Cardoso
- 10 de fevereiro, 2023

# PL2 Goal:

\textcolor{lightgray}{To use cross-validation to illustrate the evaluation of results of supervised learning using Simple Linear Regression on the Boston data set. The evaluation of results uses diverse metrics.}

- Utilizar a validação cruzada para ilustrar a avaliação dos resultados da aprendizagem supervisionada utilizando a Regressão Linear Simples no conjunto de dados de Boston. A avaliação dos resultados utiliza métricas diversas.

```{r}
# Bibliotecas
rm(list=ls(all=TRUE)) # First remove everything! 
library(MASS)         # The MASS library contains the Boston data set 
library(car)          # provides multicolinearity indicators 
library(Metrics)      # to help calculating metrics
library(caret)        # to provide folds for cross-validation
library(ggplot2)
library(lsr)
```


\newpage

## 1) The Boston data set

The Boston data set records median house values (medv) for 506 neighborhoods around Boston.

### TARGET:

- **medv:** median house value 

### PREDICTORS: 

- **crim:** per capita crime rate by town 

- **zn:** proportion of residential land zoned for lots over 25,000 sq 

- **indus:** proportion of non-retail business acres per town 

- **chas:** Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) 

- **nox:** nitric oxides concentration (parts per 10 million) 

- **rm:** average number of rooms per dwelling 

- **age:** proportion of owner-occupied units built prior to 1940 

- **dis:** weighted distances to five Boston employment centers 

- **rad:** index of accessibility to radial highways

- **tax:** full-value property-tax rate per $10,000 

- **pratio:** pupil-teacher ratio by town 

- **black:** $1000(B_k - 0.63)^2$, where $B_k$ is the proportion of [people of African American descent]by town 

- **lstat:** $\%$ lower status of the population

---

```{r}
#?Boston data(Boston) 
dim(Boston)
names(Boston)
```


\newpage

# 2) Complex linear regression for Boston (all data set)

## 2.a) Using `lm`

```{r}
#?lm to get to know lm 
lm.Boston3 <-lm(medv~lstat+rm+ptratio ,data=Boston )
lm.Boston3
vif(lm.Boston3) # no multicolinearity problem
```

## 2.b) $R^2$ and other metrics to evaluate the SLR results

```{r}
pred_medv<-predict(lm.Boston3,Boston)

# Regression metrics

# Residual Sum of Squares (RSS)
(RSS_lm.Boston3 <-sse(Boston$medv, pred_medv))

# R-Squared
(RSQ_lm.Boston3<-summary(lm.Boston3)$r.squared)

# OR
(RSQ_lm.Boston3<-1-RSS_lm.Boston3/(var(Boston$medv)*(nrow(Boston)-1)))

# Mean Squared Error (MSE)
(MSE_lm.Boston3 <- RSS_lm.Boston3 /nrow(Boston))

#Mean Absolute Error (MAE)
(MAE_lm.Boston3 <- mae(Boston$medv, pred_medv))

#....
```

\newpage

# 3) Using cross-validation to evaluate SLR performance

## 3.1) reate the data partition (10-fold)

```{r}
# Dividimos as obserações da variável Boston$medv em 10 conjuntos
V<-10
folds<-createFolds(Boston$medv, V , list = TRUE, returnTrain = FALSE)
str(folds)
                   
# to show the elements of first fold
folds$Fold01

# or
folds[[1]]
```

## 3.2)	Learning with simple linear regression based on training set minus a fold and use holdout fold to evaluate performance (repeat)

```{r}
cv.pred_medv<-matrix(NA ,nrow(Boston),1)
j=1

# Ciclo da Validação Cruzada
for(j in 1:V){
  # Retiramos sempre 1 dos conjuntos para ficar como Conjunto Teste
  lm.Boston3_ <-lm(medv~lstat+ptratio, data =Boston[-folds[[j]],]) 
  x_out <- Boston[folds[[j]],c(6,11,13)] 
  cv.pred_medv[folds[[j]]]<- predict (lm.Boston3_,x_out)
}

# Regression metrics
# Residual Sum of Squares (RSS)
(RSS_cv_lm.Boston3 <-sse(Boston$medv, cv.pred_medv))

# R-Squared
(RSQ_cv_lm.Boston3<-1-RSS_cv_lm.Boston3/sse(Boston$medv,mean(Boston$medv)))

# Mean Squared Error (MSE)
(MSE_cv_lm.Boston3 <- RSS_cv_lm.Boston3/nrow(Boston))

#Mean Absolute Error (MAE)
(MAE_cv_lm.Boston3 <- mae(Boston$medv, cv.pred_medv))

# The values obtained with cross-validation are less optimistic/more realistic
```

\newpage

# Exercícios

\textcolor{lightgray}{**EXERCISE 1:** check all steps and verify you can interpret the analysis conducted and outputs obtained}

- Verifique todas as etapas e verifique se pode interpretar a análise realizada e as saídas obtidas

> ...


---

\textcolor{lightgray}{**EXERCISE 2:** Complement the evaluation of results, both on the training set and cross- validation approaches, resorting to additional metrics}


- Complemente a avaliação dos resultados, tanto no conjunto de treinos como nas abordagens de validação cruzada, recorrendo a métricas adicionais.

> **Training and Test sets**

```{r}
set.seed(777) 
ind_train <- sample(nrow(Boston),.65*nrow(Boston)) 
Boston_train <- Boston[ind_train,] 
dim(Boston_train)

Boston_test <- Boston[-ind_train,] 
dim(Boston_test)
```

> **simple linear regression based on the training set and then using the test set to evaluate the performance**

```{r}
# learning is based on the training sample 
lm.Boston1_train <-lm(medv~lstat+rm+ptratio, data=Boston_train) 
summary(lm.Boston1_train)

# MAPE Train | Erro de Previsão 
actual1 <- Boston_train$medv
prediction1 <- (lm.Boston1_train$fitted.values)
n<-length(Boston_train$medv)
MAPE1 <- (1/n) * sum(abs((actual1 - prediction1)/actual1))
MAPE1
```


```{r}
pred.lm.Boston1_test <- predict(lm.Boston1_train ,Boston_test) 
head(pred.lm.Boston1_test)
```

```{r}
# MAPE Test | Erro de Previsão 
actual2 <- Boston_test$medv
n<-length(Boston_test$medv)
MAPE2 <- (1/n) * sum(abs((actual2 - pred.lm.Boston1_test)/actual2))
MAPE2
```






